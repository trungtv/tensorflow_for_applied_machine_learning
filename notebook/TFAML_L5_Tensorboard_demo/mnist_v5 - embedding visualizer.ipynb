{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "Code adapted from: https://github.com/decentralion/tf-dev-summit-tensorboard-tutorial/blob/master/mnist.py\n",
    "# Tf.summary\n",
    "Module tf.summary containts tensorflow operators that output \"summary\" protocolbuffer format \n",
    "Examples:  \n",
    "tf.summary.scalar  \n",
    "tf.summary.image  \n",
    "tf.summary.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trungtv/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-903e89329263>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/trungtv/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/trungtv/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist_demo/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/trungtv/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist_demo/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/trungtv/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist_demo/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist_demo/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/trungtv/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "LOGDIR = \"./mnist_demo/\"\n",
    "### MNIST EMBEDDINGS ###\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(train_dir=LOGDIR + \"data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = os.path.join(os.getcwd(), \"labels_1024.tsv\")\n",
    "SPRITES = os.path.join(os.getcwd(), \"sprite_1024.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, size_in, size_out, name='conv'):\n",
    "    with tf.name_scope(name):\n",
    "        #w = tf.Variable(tf.zeros([5, 5, size_in, size_out]), name='W')\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        #b = tf.Variable(tf.zeros([size_out]), name='B')\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name='fc'):\n",
    "    with tf.name_scope(name):\n",
    "        # w = tf.Variable(tf.zeros([size_in, size_out]), name='W')\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        # b = tf.Variable(tf.zeros([size_out]), name='B')\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_model(learning_rate):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Setup placeholders, and reshape the data\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 3)\n",
    "    # create the network \n",
    "    # first convec layer\n",
    "    conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "    # second convec layer\n",
    "    conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "    flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "    #################\n",
    "    embedding_input = flattened\n",
    "    #################\n",
    "    # embedding_size = 7 * 7 * 64\n",
    "    fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, 'fc1')\n",
    "    logits = fc_layer(fc1, 1024, 10, 'fc2')\n",
    "    \n",
    "    #compute cross entropy as our loss function \n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits=logits, labels=y))\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    # use and AdapOptimizer to train the network\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "    \n",
    "    # compute the accuracy\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    # Initialize all the variables \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR + \"5-embedding-visualizer\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    #############\n",
    "    embedding = tf.Variable(tf.zeros([1024, 7*7*64]), name=\"test_embedding\")\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.sprite.image_path = SPRITES\n",
    "    embedding_config.metadata_path = LABELS\n",
    "    # Specify the width and height of a single thumbnail.\n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "    \n",
    "    \n",
    "    # Train for 1000 steps\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        # Occasionally report accuracy \n",
    "        if i % 50 == 0:\n",
    "            [train_accuracy, s] = sess.run([accuracy, merged_summary], feed_dict={x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "            ###############\n",
    "            # Occationally calculate embedding for the test dataset   \n",
    "            sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "        # Run the training step\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.05\n",
      "step 50, training accuracy 0.75\n",
      "step 100, training accuracy 0.83\n",
      "step 150, training accuracy 0.92\n",
      "step 200, training accuracy 0.89\n",
      "step 250, training accuracy 0.95\n",
      "step 300, training accuracy 0.92\n",
      "step 350, training accuracy 0.88\n",
      "step 400, training accuracy 0.91\n",
      "step 450, training accuracy 0.92\n",
      "step 500, training accuracy 0.97\n",
      "step 550, training accuracy 0.96\n",
      "step 600, training accuracy 0.92\n",
      "step 650, training accuracy 0.96\n",
      "step 700, training accuracy 0.99\n",
      "step 750, training accuracy 0.94\n",
      "step 800, training accuracy 0.97\n",
      "step 850, training accuracy 0.93\n",
      "step 900, training accuracy 0.96\n",
      "step 950, training accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "mnist_model(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let visualize the Tensorflow graph\n",
    "tensorboard --logdir ./mnist_demo/5-embedding-visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
